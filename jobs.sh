ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256
ts -G 2 python finetune.py --batch-size-per-device 16 --num-devices 2 --model_name meta-llama/Llama-2-7b-hf --output_dir outputs/ --lr 1e-06 --num-epochs 5 --ds-config deepspeed_configs/zero_3_llama_2_7b.json --train-path /pub/scratch/xiayao/projects/utils/trainer/data/train.jsonl --special-token-path ./data/tokens.json --test-path /pub/scratch/xiayao/projects/utils/trainer/data/test.jsonl --lora --lora-rank 256